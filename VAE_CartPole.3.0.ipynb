{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify VAE_CartPole.2.1 from one frame into temporal process.\n",
    "\n",
    "Ref: *pytorch-mnist-VAE-master, VAE_CartPole.2.1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# for VAE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# for Gym env\n",
    "import pickle\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import ipdb\n",
    "\n",
    "bs = 32\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "    \n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract screemshot for cartpole env, form train-valid dataset CartPole_data.\n",
    "\n",
    "Ref: *DQN_CartPole.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class CartPole_data(object):\n",
    "    \n",
    "    def __init__(self, file_name, capacity=1):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        self.file_name = file_name\n",
    "        \n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def save(self):\n",
    "        with open(self.file_name, 'wb') as file:\n",
    "            pickle.dump(self.memory, file)\n",
    "            \n",
    "    def load(self):\n",
    "        with open(self.file_name, 'rb') as file:\n",
    "            self.memory = pickle.load(file)\n",
    "        \n",
    "    def sample(self, batch_size, h):\n",
    "#         if len(self.memory) < self.capacity:\n",
    "#             print(len(self.memory))\n",
    "#             print(self.capacity)\n",
    "#             self.load()\n",
    "#             print('loaded')\n",
    "#             print(len(self.memory))\n",
    "        \n",
    "        # randomly sample a batch of time series data, with horizon h\n",
    "        samples = []\n",
    "#         dones = []\n",
    "        i = batch_size\n",
    "        while(i > 0):\n",
    "            done = False\n",
    "            index = random.randint(0, len(self.memory) - 1 - h)\n",
    "            for triple in self.memory[index : index + h]:\n",
    "                if type(triple.next_state) == type(None):\n",
    "                    done = True\n",
    "                    break\n",
    "            if not done:\n",
    "                i = i - 1\n",
    "                samples = samples + self.memory[index : index + h]\n",
    "#                 dones = dones + [type(triple.next_state) for triple in self.memory[index : index + h]]\n",
    "        return samples\n",
    "    \n",
    "#             indexs = random.sample(range(len(self.memory)), batch_size)\n",
    "#         return [self.memory(index:index + u) for index in indexs]\n",
    "    \n",
    "    def read(self, batch_size, num):\n",
    "        return self.memory[num * batch_size: (num + 1) * batch_size - 1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "    def get_len(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = None\n",
    "b = torch.range(0,10)\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "b = [0, 5]\n",
    "\n",
    "[a[index : index + 4] for index in b]\n",
    "c = []\n",
    "c = c + a[1:4]\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    \n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "\n",
    "    slice_range = slice((screen_width - view_width) // 2,\n",
    "                        (screen_width + view_width) // 2)\n",
    "    \n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = screen.mean(axis=0)\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "screen shot size:  torch.Size([1, 1, 40, 90])\n",
      "img_flatten_size:  3600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu()[0,0,:].numpy(), cmap='gray')\n",
    "img_flatten_size = get_screen().shape[2] * get_screen().shape[3]\n",
    "print('screen shot size: ', get_screen().shape)\n",
    "img_width = get_screen().shape[3]\n",
    "print('img_flatten_size: ', img_flatten_size)\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(file_name='CartPole_data_1e5_cart_pole.txt', capacity=1e5, load=False, sample_t=4):\n",
    "    n_actions = env.action_space.n\n",
    "    memory = CartPole_data(file_name, capacity)\n",
    "    \n",
    "    if load:\n",
    "        memory.load()\n",
    "        return memory\n",
    "    \n",
    "    thre = 0\n",
    "    \n",
    "    while memory.get_len() < capacity:\n",
    "        # Initialize the environment and state\n",
    "        env.reset()\n",
    "        state = get_screen()\n",
    "        \n",
    "        for t in count():\n",
    "            # Select and perform an action\n",
    "            action = torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "            _, reward, done, _ = env.step(action.item())\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "\n",
    "            if t > 80:\n",
    "                done = True\n",
    "                \n",
    "            if done:\n",
    "                next_state = None\n",
    "            \n",
    "            if t % sample_t == sample_t - 1 or done:\n",
    "                if not done:\n",
    "                    next_state = get_screen()\n",
    "                # Store the transition in memory\n",
    "                memory.push(state, action, next_state, reward)\n",
    "                # Move to the next state\n",
    "                state = next_state\n",
    "            \n",
    "            if done:\n",
    "                if memory.get_len() > thre:\n",
    "                    thre += capacity//10\n",
    "                    print('\\rEpisode {}\\tIt Last: {}'.format(memory.get_len() + 1, t + 1))\n",
    "                    print(thre)\n",
    "                break\n",
    "\n",
    "    memory.save()\n",
    "    print('------Complete-----')\n",
    "    env.render()\n",
    "    env.close()\n",
    "    print(type(memory))\n",
    "    return memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading or generating training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data_generation(file_name='CartPole_data_1e5_cart_pole.txt', num_episodes=50000)\n",
    "# train_data = data_generation(file_name='CartPole_data_3e4_cart_pole.txt', load=True)\n",
    "train_data = data_generation(file_name='CartPole_data_1e3_st5.txt', load=True)\n",
    "# train_data = data_generation(file_name='CartPole_data_1e5_st5.txt', load=True)\n",
    "# train_data = data_generation(file_name='CartPole_data_test_5e3_cart_pole.txt', load=True)\n",
    "# test_data = data_generation(file_name='CartPole_data_test_5e3_cart_pole.txt', num_episodes=2500)\n",
    "# test_data = data_generation(file_name='CartPole_data_test_1e3_cart_pole.txt', load=True)\n",
    "test_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CartPole_data"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, h, x_dim=10, h_dim1=10, h_dim2=10, z_dim=10):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "#         x_dim = x_dim / h    # devide x into h channels\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc61 = nn.Linear(h_dim1, x_dim)\n",
    "        self.fc62 = nn.Linear(h_dim1, x_dim)\n",
    "        # latent variable transform part\n",
    "        self.fc7 = nn.Linear(z_dim * (h - 1), z_dim)    # mu\n",
    "        self.fc8 = nn.Linear(z_dim, z_dim)    # sigma\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu_e, log_var_e\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc61(h)), self.fc62(h) # mu_d, log_var_d\n",
    "    \n",
    "    def mu_t(self, z_bs):\n",
    "        return self.fc7(z_bs)\n",
    "    \n",
    "    def log_var_t(self):\n",
    "        return self.fc8(torch.ones(z_dim).to(device))    #???\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu_e, log_var_e = self.encoder(x.view(-1, img_flatten_size))\n",
    "        z = self.sampling(mu_e, log_var_e)\n",
    "        mu_d, log_var_d = self.decoder(z)\n",
    "        mu_t = self.mu_t(torch.index_select(z.view(bs, -1), 1, torch.arange(0, z_dim * (h - 1)).long().to(device)))\n",
    "        return mu_e, log_var_e, mu_d, log_var_d, \\\n",
    "               mu_t, self.log_var_t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational bottleneck for temperal sequence.\n"
     ]
    }
   ],
   "source": [
    "beta = 20\n",
    "is_temperal = True\n",
    "\n",
    "# Variational bottleneck for temperal sequence\n",
    "if is_temperal:\n",
    "    print(\"Variational bottleneck for temperal sequence.\")\n",
    "    def loss_function(x, mu_e, log_var_e, mu_d, log_var_d, mu_t, log_var_t):\n",
    "#         # reconstruction error\n",
    "#         ReconL = -0.5 * ((x - mu_d) * (x - mu_d) / log_var_d.exp()).sum()\n",
    "        # reconstruction error\n",
    "        ReconL = -F.binary_cross_entropy(mu_d, x.view(-1, img_flatten_size), reduction='sum')\n",
    "        # entropy\n",
    "#         betaH = \n",
    "        #KL\n",
    "        betaKL = 0.5 * beta * ((1 + log_var_e).sum() -  (1 + log_var_e[h-1::h]).sum() \\\n",
    "                               - log_var_e.exp().sum() + log_var_e[h-1::h].exp().sum() \\\n",
    "                               - mu_e.pow(2).sum() + mu_e[h-1::h].pow(2).sum())\n",
    "        # transition error\n",
    "#         TransL = 0.5 * beta * (log_var_e[h-1::h] + 1 - log_var_t - (mu_e[h-1::h] - mu_t).pow(2) \\\n",
    "#                                 / log_var_t.exp()).sum()\n",
    "        Elog_p = log_var_e[h-1::h] + 1\n",
    "        Elog_q = log_var_t \\\n",
    "                 +(log_var_e[h-1::h].exp() + mu_e[h-1::h].pow(2) \\\n",
    "                 - 2 * mu_e[h-1::h] * mu_t + mu_t.pow(2)) \\\n",
    "                 / (log_var_t.exp() + 1e-15)\n",
    "        TransL = 0.5 * beta * (Elog_p - Elog_q).sum()\n",
    "#         betaH *= 0\n",
    "#         return -(ReconL + TransL + betaH + betaKL), -ReconL, -TransL, -betaH, -betaKL\n",
    "        return -(ReconL + TransL + betaKL), -ReconL, -TransL, torch.Tensor([0]), -betaKL\n",
    "\n",
    "# Variational bottleneck for i.i.d. data\n",
    "else:\n",
    "    print(\"Variational bottleneck for i.i.d. data.\")\n",
    "    def loss_function(x, mu_e, log_var_e, mu_d, log_var_d, mu_t, log_var_t):\n",
    "        REC = -F.binary_cross_entropy(mu_d, x.view(-1, img_flatten_size), reduction='sum')\n",
    "        KLD = 0.5 * beta * (1 + log_var_e - log_var_e.exp() - mu_e.pow(2)).sum()\n",
    "        return -(REC + KLD), -REC, torch.Tensor([0]), torch.Tensor([0]), -KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([ 1,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(1,5)\n",
    "print(a)\n",
    "print(a * a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.range(1,3)\n",
    "a*a\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.range(0,12)\n",
    "a = a[:]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, epochs):\n",
    "    vae.train()\n",
    "    train_loss, recon_loss, trans_loss, betaH_loss, betaKL_loss = 0, 0, 0, 0, 0\n",
    "    capacity = train_data.get_len()\n",
    "    \n",
    "    for batch_idx in range(capacity // bs):\n",
    "#         data = data.cuda()\n",
    "        transitions = train_data.sample(bs, h)\n",
    "        data = torch.cat(Transition(*zip(*transitions)).state)\n",
    "        data = data.to(device)\n",
    "        next_states = torch.cat(Transition(*zip(*transitions)).next_state)\n",
    "        next_states = next_states[h - 1::h].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        mu_e, log_var_e, mu_d, log_var_d, mu_t, log_var_t = vae(data)\n",
    "        with torch.no_grad():\n",
    "            mu_e_next, log_var_e_next = vae.encoder(next_states.view(-1, img_flatten_size))\n",
    "            z_next = vae.sampling(mu_e_next, log_var_e_next)\n",
    "        loss, ReconL, TransL, betaH, betaKL = \\\n",
    "            loss_function(data.view(-1, img_flatten_size), mu_e, log_var_e, \\\n",
    "                          mu_d, log_var_d, mu_t, log_var_t)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        recon_loss += ReconL.item()\n",
    "        trans_loss += TransL.item()\n",
    "        betaH_loss += betaH.item()\n",
    "        betaKL_loss += betaKL.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= ((capacity // bs)*bs)\n",
    "    recon_loss /= ((capacity // bs)*bs)\n",
    "    trans_loss /= ((capacity // bs)*bs)\n",
    "    betaH_loss /= ((capacity // bs)*bs)\n",
    "    betaKL_loss /= ((capacity // bs)*bs)\n",
    "\n",
    "    if epoch % (epochs // 10) == 0:\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss))\n",
    "        print('Total Loss', -loss.item())\n",
    "        print('ReconL, TransL, betaH, betaKL', ReconL.item(), TransL.item(), betaH.item(), betaKL.item())\n",
    "    return train_loss, recon_loss, trans_loss, betaH_loss, betaKL_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(epoch, epochs):\n",
    "#     vae.eval()\n",
    "#     test_loss= 0\n",
    "#     capacity = test_data.get_len()\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx in range(capacity // bs):\n",
    "# #         for batch_idx in range(3):\n",
    "# #         data = data.cuda()\n",
    "#             transitions = test_data.read(bs, batch_idx)\n",
    "# #             transitions = test_data.sample(bs)\n",
    "#             data = torch.cat(Transition(*zip(*transitions)).state)\n",
    "#             data = data.to(device)\n",
    "#             recon_batch, mu, log_var = vae(data)\n",
    "#             loss, _, _ = loss_function(recon_batch, data, mu, log_var)\n",
    "#             test_loss += loss.item()\n",
    "#     test_loss = test_loss / ((capacity // bs)*bs)\n",
    "#     if epoch % (epochs // 10) == 0:\n",
    "#         print('====> Test average loss: {:.4f}'.format(test_loss))\n",
    "#     return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_plot(epochs):\n",
    "    train_test_loss_hist = [[], [], [], [], []]\n",
    "    num = np.arange(0, 5)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(epoch, epochs)\n",
    "#         test_loss = test(epoch, epochs)\n",
    "        for item in num:\n",
    "            train_test_loss_hist[item].append(train_loss[item])\n",
    "        \n",
    "#     for loss in train_test_loss_hist:\n",
    "#         plt.plot(np.arange(1, epochs + 1), loss[:])\n",
    "    plt.plot(np.arange(1, epochs + 1), train_test_loss_hist[0])\n",
    "    plt.plot(np.arange(1, epochs + 1), train_test_loss_hist[1])\n",
    "    plt.plot(np.arange(1, epochs + 1), train_test_loss_hist[2])\n",
    "    plt.plot(np.arange(1, epochs + 1), train_test_loss_hist[4])\n",
    "    plt.title('Loss Function History, z_dim={}'.format(z_dim))\n",
    "#     plt.legend(['train_loss', 'recon_loss', 'trans_loss', 'betaH_loss', 'betaKL_loss'])\n",
    "    plt.legend(['total_loss', 'reconstruction_loss', 'transition_loss', 'KL_loss'])\n",
    "    plt.show()\n",
    "    return train_test_loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-08-06 15:52:09'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = 20\n",
    "# def train_reconstruct():\n",
    "#     # show the random sampled training set\n",
    "#     transitions = test_data.sample(rows ** 2)\n",
    "#     data = torch.cat(Transition(*zip(*transitions)).state)\n",
    "#     save_image(data.view(rows ** 2, 1, 40, img_width), \\\n",
    "#                    './samples/1training_set' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.png', \\\n",
    "#                    nrow=rows)\n",
    "    \n",
    "#     # show the reconstructed imgs correspond to the training set\n",
    "#     data = data.to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     recon_batch, _, _ = vae(data)\n",
    "#     save_image(recon_batch.view(rows ** 2, 1, 40, img_width), \\\n",
    "#                    './samples/2reconstruction_training' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.png', \\\n",
    "#                    nrow=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 4261.7748\n",
      "Total Loss -73944.5703125\n",
      "ReconL, TransL, betaH, betaKL 70905.8828125 1332.65380859375 0.0 1706.0321044921875\n",
      "====> Epoch: 2 Average loss: 2290.2587\n",
      "Total Loss -74048.8046875\n",
      "ReconL, TransL, betaH, betaKL 72802.109375 820.1691284179688 0.0 426.5240173339844\n",
      "====> Epoch: 3 Average loss: 2213.3451\n",
      "Total Loss -70534.9375\n",
      "ReconL, TransL, betaH, betaKL 69927.8359375 515.7687377929688 0.0 91.33456420898438\n",
      "====> Epoch: 4 Average loss: 2196.9208\n",
      "Total Loss -68438.25\n",
      "ReconL, TransL, betaH, betaKL 67866.703125 522.3682861328125 0.0 49.18263244628906\n",
      "====> Epoch: 5 Average loss: 2159.8134\n",
      "Total Loss -67875.640625\n",
      "ReconL, TransL, betaH, betaKL 67109.796875 543.3793334960938 0.0 222.46029663085938\n",
      "====> Epoch: 6 Average loss: 2110.4121\n",
      "Total Loss -67437.375\n",
      "ReconL, TransL, betaH, betaKL 64847.1171875 694.769775390625 0.0 1895.481201171875\n",
      "====> Epoch: 7 Average loss: 2024.8813\n",
      "Total Loss -64569.37109375\n",
      "ReconL, TransL, betaH, betaKL 61550.48046875 641.6644287109375 0.0 2377.22802734375\n",
      "====> Epoch: 8 Average loss: 1991.4772\n",
      "Total Loss -63310.98828125\n",
      "ReconL, TransL, betaH, betaKL 59504.375 714.384521484375 0.0 3092.23095703125\n",
      "====> Epoch: 9 Average loss: 1941.0739\n",
      "Total Loss -59020.03125\n",
      "ReconL, TransL, betaH, betaKL 54809.02734375 790.4076538085938 0.0 3420.595703125\n",
      "====> Epoch: 10 Average loss: 1879.9304\n",
      "Total Loss -60521.31640625\n",
      "ReconL, TransL, betaH, betaKL 57238.73046875 680.2327880859375 0.0 2602.352294921875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.4253783226013184s\n"
     ]
    }
   ],
   "source": [
    "train_lost_hist = []\n",
    "z_dims = np.array([8])\n",
    "h = 5    # !Note: h is horizon + 1\n",
    "\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "for z_dim in z_dims:\n",
    "    # build model\n",
    "    vae = VAE(h, x_dim=img_flatten_size, h_dim1=512, h_dim2=256, z_dim=z_dim)\n",
    "    vae = vae.to(device)\n",
    "    optimizer = optim.Adam(vae.parameters())\n",
    "    train_plot(10)\n",
    "#     train_lost_hist.append(train_plot(100))\n",
    "#     train_reconstruct()\n",
    "    \n",
    "# plt.plot(np.array(train_lost_hist)[:, :, 0].squeeze().transpose())\n",
    "# plt.title('Train loss for different z_dim')\n",
    "# legend = ['z_dim=' + str(z_dim) for z_dim in z_dims]\n",
    "# plt.legend(legend)\n",
    "# plt.ylim([140, 260])\n",
    "# plt.show()\n",
    "\n",
    "toc = time.time()\n",
    "print(\"time: \" + str(toc - tic) + \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"Vectorized version: \" + str(1000*(toc-tic)) + \"ms\")\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i]*b[i]\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"For loop: \" + str(1000*(toc-tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.arange(1,16)\n",
    "print(aa)\n",
    "index = torch.arange(0, 4)\n",
    "print(torch.index_select(aa.view(3, -1), 1, index))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot training loss for all dims\n",
    "# plt.plot(np.array(train_lost_hist)[:, :, 0].squeeze().transpose())\n",
    "# plt.title('Train loss for different z_dim')\n",
    "# legend = ['z_dim=' + str(z_dim) for z_dim in z_dims]\n",
    "# plt.legend(legend)\n",
    "# plt.ylim([140, 260])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae.state_dict(), 'vae_data1e5_ep100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VAE structure: \\n\", vae)\n",
    "print(\"NN for transistion model: \\n\", list(vae.parameters())[16][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualization of the training results of the VAE\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "#     transitions, dones = train_data.sample(bs, h)\n",
    "    bs = 1000\n",
    "    transitions = train_data.sample(bs, h)\n",
    "    data = torch.cat(Transition(*zip(*transitions)).state)\n",
    "    data = data.to(device)\n",
    "    mu_e, log_var_e, mu_d, log_var_d, mu_t, log_var_t = vae(data)\n",
    "    loss, ReconL, TransL, betaH, betaKL = \\\n",
    "        loss_function(data.view(-1, img_flatten_size), mu_e, log_var_e, \\\n",
    "                      mu_d, log_var_d, mu_t, log_var_t)\n",
    "#     z_h = vae.sampling(mu_t, log_var_t.repeat(bs,1))\n",
    "#     z_h = vae.sampling(mu_t, torch.ones_like(log_var_t.repeat(bs,1)))\n",
    "#     mu_h, _ = vae.decoder(z_h)\n",
    "    mu_h, _ = vae.decoder(mu_t)\n",
    "    \n",
    "#     print('Error of transistion z: %6.3f' % (((z_h - mu_e[h-1::h]).pow(2).mean() / z_h.pow(2).mean()).item()))\n",
    "    print('Error of transistion mu_t: %6.3f' % (((mu_t - mu_e[h-1::h]).pow(2).mean() / mu_t.pow(2).mean()).item()))\n",
    "    print('Abs Mean value of estimateted z: ',  [round(it, 2) for it in mu_t.abs().mean(0).tolist()])\n",
    "    print('Sigma of estimated z: ',  [round(it, 2) for it in log_var_t.exp().tolist()])\n",
    "    \n",
    "#     cols = bs\n",
    "#     rows = h\n",
    "    rows = 4\n",
    "    cols = h\n",
    "#     print(dones)\n",
    "    fig1 = plt.figure(figsize=(12, 7))\n",
    "    plt.title('Origional images')\n",
    "    for i in range(1, cols*rows + 1):\n",
    "        img = data[i - 1].view(40, 90).to('cpu')\n",
    "        fig1.add_subplot(rows, cols, i)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    alpha = 0.5\n",
    "    fig2 = plt.figure(figsize=(12, 7))\n",
    "    plt.title('Reconstruct images')\n",
    "    for i in range(0, cols*rows):\n",
    "        if i % h != h -1:\n",
    "            img = mu_d[i].view(40, 90).to('cpu') #- data[i].view(40, 90).to('cpu') * alpha\n",
    "        else:\n",
    "            img = mu_h[int((i + 1) / h - 1)].view(40, 90).to('cpu') - data[i].view(40, 90).to('cpu') * alpha\n",
    "        fig2.add_subplot(rows, cols, i + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    fig3 = plt.figure(figsize=(12, 7))\n",
    "    plt.title('Origional images need to be predict')\n",
    "    for i in range(1, cols*rows + 1):\n",
    "        img = data[h * i - 1].view(40, 90).to('cpu')\n",
    "        fig3.add_subplot(rows, cols, i)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    fig4 = plt.figure(figsize=(12, 7))\n",
    "    plt.title('Predicted images')\n",
    "    for i in range(1, cols*rows + 1):\n",
    "        img = mu_h[i - 1].view(40, 90).to('cpu')\n",
    "        fig4.add_subplot(rows, cols, i)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization for reconstruction when z_dim = 2\n",
    "variance = 4\n",
    "if z_dim == 2:\n",
    "    with torch.no_grad():\n",
    "        x = np.linspace(-variance, variance, rows)\n",
    "        y = np.linspace(-variance, variance, rows)\n",
    "        xv, yv = np.meshgrid(x, y)\n",
    "        z = np.concatenate((xv.reshape(rows ** 2,1),yv.reshape(rows ** 2,1)), axis=1)\n",
    "        z = torch.from_numpy(z).float()\n",
    "        z = z.to(device)\n",
    "        sample = vae.decoder(z)\n",
    "\n",
    "        save_image(sample.view(rows ** 2, 1, 40, img_width), \\\n",
    "                   './samples/3reconstruction_z_dim=2' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.png', \\\n",
    "                   nrow=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of mu of randomly sampled training set\n",
    "transitions = train_data.sample(10000)\n",
    "data = torch.cat(Transition(*zip(*transitions)).state)\n",
    "data = data.to(device)\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    recon_batch, mu, log_var = vae(data)\n",
    "    z = vae.sampling(mu, log_var)\n",
    "    mu = mu.to('cpu')\n",
    "    z = z.to('cpu')\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(mu[:, 4], mu[:, 5], label='mu', alpha=0.9, s=1)\n",
    "# plt.scatter(z[:, 0], z[:, 1], label='sample', alpha=0.7, s=1)\n",
    "plt.legend()\n",
    "plt.title('Latent variable distribution')\n",
    "# plt.xlim([-3.5, 3.5])\n",
    "# plt.ylim([-3.5, 3.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vusualization of reconstruction of randomly sampled z\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(64, z_dim)\n",
    "    z = z.to(device)\n",
    "    sample = vae.decoder(z)\n",
    "    print(sample.shape)\n",
    "    save_image(sample.view(64, 1, 40, img_width), './samples/' + strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
